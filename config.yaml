# DocGenAI Configuration File
# Configuration for code documentation generation

# AI Model Configuration
model:
  # Model selection (platform-aware)
  # macOS: Uses MLX-optimized model automatically
  # Linux/Windows: Uses standard transformers model
  mlx_model: "mlx-community/DeepSeek-Coder-V2-Lite-Instruct-4bit"
  transformers_model: "TechxGenus/DeepSeek-Coder-V2-Lite-Instruct-AWQ"

  # Generation parameters
  temperature: 0.1
  max_tokens: 4000
  top_p: 0.9
  min_p: 0.05
  top_k: 50
  do_sample: true

  # Quantization settings (non-MLX platforms)
  quantization: "4bit"
  load_in_4bit: true
  load_in_8bit: false

  # Model caching and offline behavior
  session_cache: true
  cache_model_files: true
  offline_mode: true
  check_for_updates: false
  force_download: false
  local_files_only: true

  # Hardware optimization
  device_map: "auto"
  torch_dtype: "auto"
  trust_remote_code: true

# Caching Configuration
cache:
  enabled: true
  cache_dir: ".cache/docgenai"
  model_cache_dir: ".cache/models"
  max_cache_size_mb: 2000
  generation_ttl_hours: 24
  auto_cleanup: true

# Output Configuration
output:
  dir: "output"
  filename_template: "{name}_documentation.md"
  include_architecture: true
  include_code_stats: true
  markdown_style: "github"
  metadata_mode: "file"  # Options: "none", "footer", "file"
  architecture_type: "comprehensive"  # Options: "standard", "comprehensive"

# File Selection Configuration
file_selection:
  max_files: 50
  max_file_size: 10000
  include_patterns:
    - "*.py"
    - "*.js"
    - "*.ts"
    - "*.jsx"
    - "*.tsx"
    - "*.go"
    - "*.java"
    - "*.cpp"
    - "*.c"
    - "*.h"
    - "*.rs"
    - "*.rb"
    - "*.php"
  exclude_patterns:
    - "*/node_modules/*"
    - "*/__pycache__/*"
    - "*/vendor/*"
    - "*/build/*"
    - "*/dist/*"
    - "*/target/*"
    - "*/.git/*"
    - "*/venv/*"
    - "*/env/*"

# Chunking Configuration
chunking:
  max_chunk_tokens: 12000
  overlap_tokens: 500
  prefer_file_boundaries: true
  signature_threshold: 5000
  safety_margin: 0.75

# Chain Configuration
chains:
  default_strategy: "single_pass"
  enable_refinement: false
  enable_synthesis: true

# Template Configuration
templates:
  dir: "src/docgenai/templates"
  doc_template: "default_doc_template.md"
  style_guide: "default_style_guide.md"
  author: ""
  organization: ""
  project_name: ""
  project_version: ""

# Generation Configuration
generation:
  doc_type: "both"
  project_type: "auto"
  detail_level: "module_plus_strategic_class"
  max_files_per_group: 8
  use_chaining: false
  chain_strategy: "simple"

# Logging Configuration
logging:
  level: "INFO"
  verbose_level: "DEBUG"
  format: "%(message)s"
  verbose_format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  console: true
  file: false

# Performance Configuration
performance:
  max_memory_usage_gb: 16
  auto_detect_gpu: true
  prefer_gpu: true
